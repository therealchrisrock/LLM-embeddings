import json
import faiss
import numpy as np
from pathlib import Path

from definitions import ROOT_DIR

# Paths
EMBEDDINGS_FILE = f"{ROOT_DIR}/data/embeddings/templ_embeddings.json"
FAISS_INDEX_DIR = f"{ROOT_DIR}/data/faiss"
FAISS_INDEX_FILE = f"{FAISS_INDEX_DIR}/templ.index"

# Most OpenAI text-embedding-ada-002 embeddings are 1536 dimensions.
EMBEDDING_DIMENSION = 1536


def load_embeddings(filepath: str) -> list[dict]:
    """
    Load embeddings from a JSON file that was generated by generate_embeddings.py.

    Each item should look like:
    {
      "chunk": {
        "source": "...",
        "chunk": "text..."
      },
      "embedding": [0.0219, 0.0022, ... ]  # list of floats
    }
    """
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)
    if not isinstance(data, list):
        raise ValueError(f"Expected a list of embeddings in {filepath}, got {type(data)}")
    return data


def build_faiss_index(embeddings: list[dict]) -> faiss.Index:
    """
    Build a Faiss index (IndexFlatL2) for the given embeddings.

    :param embeddings: List of dict objects with "embedding": list of floats
    :return: A FAISS index containing all vectors.
    """
    # Initialize a Faiss index of the appropriate dimension
    index = faiss.IndexFlatL2(EMBEDDING_DIMENSION)

    # Convert embeddings to a NumPy array of shape (num_vectors, EMBEDDING_DIMENSION)
    vectors = []
    for emb in embeddings:
        if "embedding" not in emb:
            raise ValueError("Embedding dict missing 'embedding' key.")
        vectors.append(emb["embedding"])

    # Convert list of lists into float32 NumPy array
    vectors_np = np.array(vectors, dtype=np.float32)

    # Add to the Faiss index
    index.add(vectors_np)

    return index


def save_faiss_index(index: faiss.Index, path: str):
    """
    Save the Faiss index to disk.
    """
    faiss.write_index(index, path)


def load_faiss_index(path: str) -> faiss.Index:
    """
    Load an existing Faiss index from disk.
    """
    return faiss.read_index(path)


def search_index(index: faiss.Index, query_embedding: list[float], top_k: int = 3):
    """
    Perform a nearest-neighbor search on the Faiss index.

    :param index: Faiss index to query.
    :param query_embedding: A single embedding vector for the query (list of floats).
    :param top_k: Number of nearest neighbors to retrieve.
    :return: (distances, indices) from Faiss. Each is a 2D array of shape (1, top_k).
    """
    # Convert the query embedding to a (1, dimension) float32 array
    query_np = np.array([query_embedding], dtype=np.float32)
    distances, indices = index.search(query_np, top_k)
    return distances, indices


if __name__ == "__main__":
    # 1. Ensure the FAISS output directory exists
    Path(FAISS_INDEX_DIR).mkdir(parents=True, exist_ok=True)

    # 2. Load embeddings from templ_embeddings.json
    try:
        embeddings_data = load_embeddings(EMBEDDINGS_FILE)
    except FileNotFoundError:
        print(f"ERROR: Could not find embeddings file at {EMBEDDINGS_FILE}.")
        exit(1)

    # 3. Build Faiss index
    index = build_faiss_index(embeddings_data)
    print(f"Built FAISS index with {index.ntotal} embeddings.")

    # 4. Save index to disk
    save_faiss_index(index, FAISS_INDEX_FILE)
    print(f"FAISS index saved to: {FAISS_INDEX_FILE}")

    # (Optional) Demonstration of searching:
    # Suppose we want to test the first chunk's embedding as a query
    if embeddings_data:
        sample_query_embedding = embeddings_data[0]["embedding"]
        dists, idxs = search_index(index, sample_query_embedding, top_k=3)
        print("Sample query results:")
        print("Distances:", dists)
        print("Indices:", idxs)
        # You can map idxs[0][i] back to embeddings_data[idx] to see which chunk was retrieved.